with tab6:
    st.header("Real-Time Recalibration Simulation")

    # --- User Controls ---
    st.subheader("Configure Shock Simulation")
    user_roll = st.number_input("Rolling Window Length", min_value=10, max_value=100, value=60, step=5)
    shock_end_date = st.date_input("Shock End Date", value=pd.to_datetime("2024-11-01"))

    # --- Determine Shock Start per Currency ---
    latest_dates = df.groupby("Currency")["Date"].max().reset_index()
    latest_dates["ShockStart"] = latest_dates["Date"] + pd.offsets.BDay(1)
    latest_dates["ShockEnd"] = pd.to_datetime(shock_end_date)

    # --- Simulate Shocked Data ---
    st.subheader("Simulating Shocked FX Data...")
    all_shocked = []
    for _, row in latest_dates.iterrows():
        ccy = row["Currency"]
        start, end = row["ShockStart"], row["ShockEnd"]
        df_ccy = df[df["Currency"] == ccy].copy()

        # Extend with synthetic shock dates
        date_range = pd.date_range(start=start, end=end, freq="B")
        last_close = df_ccy[df_ccy["Date"] == df_ccy["Date"].max()]["Close"].values[0]
        synthetic_df = pd.DataFrame({
            "Currency": ccy,
            "Date": date_range,
            "Close": last_close * np.cumprod(np.random.normal(1.002, 0.01, len(date_range)))
        })
        combined = pd.concat([df_ccy[["Currency", "Date", "Close"]], synthetic_df], ignore_index=True)
        combined.sort_values("Date", inplace=True)
        combined["LogReturn_Shocked"] = combined.groupby("Currency")["Close"].transform(lambda x: np.log(x).diff())
        combined["Volatility"] = combined.groupby("Currency")["LogReturn_Shocked"].transform(lambda x: x.rolling(user_roll).std()) * ANNUALIZE
        all_shocked.append(combined)

    test_df = pd.concat(all_shocked).dropna()
    test_df.to_csv("reuters_gfx_test_data.csv", index=False)
    st.success("📁 Test data with volatility shocks created and saved as `reuters_gfx_test_data.csv`.")

    # --- Load & Recalibrate ---
    st.subheader("Recalibrated Thresholds Using Test Data")
    dynamic_recalibrated = test_df.groupby("Currency").agg(
        AvgVol_Shocked=("Volatility", "mean"),
        New95thPct=("Volatility", lambda x: x.quantile(PCT_THRESHOLD)),
        NewEVT=("Volatility", lambda x: genpareto.ppf(0.999, *genpareto.fit(x[x > x.quantile(EVT_TAIL_PCT)])))
    ).reset_index()

    merged = df_summary[["Currency", "ManualThreshold"]].merge(dynamic_recalibrated, on="Currency", how="inner")
    st.dataframe(merged, use_container_width=True)

    fig = px.bar(merged.melt(id_vars="Currency", value_vars=["ManualThreshold", "New95thPct", "NewEVT"]),
                 x="Currency", y="value", color="variable", barmode="group",
                 title="Manual vs Recalibrated Thresholds (Post-Volatility Shock)",
                 labels={"value": "Threshold", "variable": "Method"})
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("Insight")
    st.markdown("""
    - Manual thresholds remain static despite simulated FX swings.
    - Dynamic thresholds increase based on volatility post-shock.
    - Adaptive models ensure more responsive alert calibration.
    """)
