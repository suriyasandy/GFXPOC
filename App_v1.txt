import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from arch import arch_model
from scipy.stats import genpareto, kurtosis, skew

ROLL_WINDOW = 60
ANNUALIZE = np.sqrt(252)
PCT_THRESHOLD = 0.95
EVT_TAIL_PCT = 0.995

@st.cache_data
def load_fx_data():
    df = pd.read_csv("reuters_fx_data.csv")
    df["Date"] = pd.to_datetime(df["Date"])
    df.sort_values(["Currency", "Date"], inplace=True)
    df["LogReturn"] = df.groupby("Currency")["Close"].transform(lambda x: np.log(x).diff())
    df["Volatility"] = df.groupby("Currency")["LogReturn"].transform(lambda x: x.rolling(ROLL_WINDOW).std()) * ANNUALIZE
    return df.dropna()

df = load_fx_data()

def assign_manual_group(vol):
    if vol < 0.07:
        return "Group 1"
    elif vol < 0.50:
        return "Group 2"
    elif vol < 0.60:
        return "Group 3"
    else:
        return "Group 4"

def compute_thresholds_per_currency(df):
    summary = []
    for ccy, group in df.groupby("Currency"):
        vol_series = group["Volatility"].dropna()
        avg_vol = vol_series.mean()
        manual_group = assign_manual_group(avg_vol)
        manual_threshold = {"Group 1": 0.10, "Group 2": 0.25, "Group 3": 0.55, "Group 4": 0.80}[manual_group]

        am = arch_model(vol_series, vol='GARCH', p=1, q=1)
        res = am.fit(disp="off")
        forecast = res.forecast(horizon=1).variance.values[-1][0] ** 0.5

        tail_data = vol_series[vol_series > vol_series.quantile(EVT_TAIL_PCT)]
        evt_params = genpareto.fit(tail_data)
        evt_threshold = genpareto.ppf(0.999, *evt_params)

        smile_rr = skew(group["LogReturn"].dropna()) * 0.02
        smile_bf = (kurtosis(group["LogReturn"].dropna()) - 3) * 0.01
        atm = avg_vol
        smile_threshold = atm + 1.0 * smile_rr + 1.0 * smile_bf

        summary.append({
            "Currency": ccy,
            "AvgVol": avg_vol,
            "ManualGroup": manual_group,
            "ManualThreshold": manual_threshold,
            "GARCH_Forecast": forecast,
            "95th_Pct": vol_series.quantile(PCT_THRESHOLD),
            "EVT_Threshold": evt_threshold,
            "ATM": atm,
            "RR": smile_rr,
            "BF": smile_bf,
            "Smile_Threshold": smile_threshold
        })
    return pd.DataFrame(summary)

df_summary = compute_thresholds_per_currency(df)

# UI layout
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["Overview", "Thresholds", "Cross Simulation", "Smile Threshold", "Smile Visuals", "Recalibration Simulation"])
with tab1:
    st.title("FX Volatility Thresholding: Manual vs Dynamic")

    st.subheader("ðŸ“Œ Business Use Case")
    st.markdown("""
    In institutional FX markets, trades are monitored for **rate deviations** from market benchmarks.
    A key component of this is **volatility thresholding**, which helps:
    - Flag trades with excessive deviation.
    - Ensure fairness, reduce risk, and maintain compliance.

    Currently, operations teams use **static thresholds** per currency, based on manual grouping logic.
    But these thresholds:
    - Donâ€™t adapt to changing market conditions.
    - Fail to account for structural behaviors like **volatility clustering** or **option smiles**.
    """)

    st.subheader("ðŸ“‰ Manual Approach (Baseline)")
    st.markdown("""
    - Currencies are bucketed into 4 fixed groups (based on average volatility ranges).
    - Each group has a fixed threshold (e.g., 0.10, 0.25...).
    - These thresholds are static and reviewed annually or post-incident.

    **Limitations**:
    - Outdated during regime shifts.
    - Not tailored to individual currency behavior.
    - No support for cross-currency or structural features like skew or RR/BF.
    """)

    st.subheader("ðŸš€ Our Dynamic Approach")
    st.markdown("""
    We simulate and compare **multiple thresholding methods**:
    - ðŸ“ˆ GARCH: Captures volatility clustering.
    - ðŸ”º EVT: Captures extreme tail risks.
    - ðŸ§  Smile-based logic: Uses implied volatility structure (ATM, Risk Reversal, Butterfly).
    - ðŸ“Š Rolling statistics & 95th percentile comparisons.
    - ðŸ” Cross-pair thresholding and real-time recalibration simulations.

    All results are:
    - Transparent & visual.
    - Easy to interpret.
    - Designed for **weekly recalibration** instead of static thresholds.
    """)

    st.success("Use the tabs above to compare manual thresholds with smarter, data-driven models!")


with tab2:
    st.header("Threshold Comparison")
    st.dataframe(df_summary, use_container_width=True)

    sel = st.selectbox("Select Currency", df["Currency"].unique(), key="tab2_currency")
    series = df[df["Currency"] == sel]
    summary = df_summary[df_summary["Currency"] == sel].iloc[0]

    fig = px.line(series, x="Date", y="Volatility", title=f"{sel} Volatility & Thresholds")
    for label in ["ManualThreshold", "GARCH_Forecast", "95th_Pct", "EVT_Threshold", "Smile_Threshold"]:
        fig.add_hline(y=summary[label], line_dash="dot", annotation_text=label)
    st.plotly_chart(fig, use_container_width=True)

with tab3:
    st.header("Cross-Currency Thresholding")
    col1, col2 = st.columns(2)
    with col1:
        base = st.selectbox("Base Currency", df['Currency'].unique(), key="base_ccy")
    with col2:
        quote = st.selectbox("Quote Currency", df['Currency'].unique(), key="quote_ccy")

    base_vals = df_summary[df_summary["Currency"] == base].select_dtypes(include=np.number).mean()
    quote_vals = df_summary[df_summary["Currency"] == quote].select_dtypes(include=np.number).mean()

    evt_cross = np.sqrt(base_vals['EVT_Threshold']**2 + quote_vals['EVT_Threshold']**2)
    smile_cross = np.sqrt(base_vals['Smile_Threshold']**2 + quote_vals['Smile_Threshold']**2)
    manual_cross = max(
        df_summary[df_summary["Currency"] == base]["ManualThreshold"].values[0],
        df_summary[df_summary["Currency"] == quote]["ManualThreshold"].values[0]
    )

    st.subheader("Cross-Pair Combined Thresholds")
    st.metric("Cross Manual", f"{manual_cross:.4f}")
    st.metric("Cross EVT", f"{evt_cross:.4f}")
    st.metric("Cross Smile", f"{smile_cross:.4f}")

    comp_df = pd.DataFrame({
        "Method": ["Manual", "EVT", "Smile"],
        base: [
            df_summary[df_summary["Currency"] == base]["ManualThreshold"].values[0],
            base_vals["EVT_Threshold"],
            base_vals["Smile_Threshold"]
        ],
        quote: [
            df_summary[df_summary["Currency"] == quote]["ManualThreshold"].values[0],
            quote_vals["EVT_Threshold"],
            quote_vals["Smile_Threshold"]
        ]
    })

    fig = go.Figure()
    for method in comp_df["Method"]:
        fig.add_trace(go.Bar(name=method, x=["Base", "Quote"], y=comp_df[comp_df["Method"] == method].iloc[0, 1:].values))

    fig.update_layout(title=f"Base vs Quote Thresholds ({base} / {quote})", barmode="group", xaxis_title="Leg", yaxis_title="Threshold")
    st.plotly_chart(fig, use_container_width=True)

with tab4:
    tab4_sub1, tab4_sub2 = st.tabs(["Smile Threshold", "What is Smile?"])

    with tab4_sub1:
        st.header("Smile-Justified Simulation (Auto)")
        sel = st.selectbox("Select Currency", df_summary["Currency"], key="tab4_currency")
        row = df_summary[df_summary["Currency"] == sel].iloc[0]

        st.write(f"ATM: {row['ATM']:.4f}, RR: {row['RR']:.4f}, BF: {row['BF']:.4f}")
        alpha = st.slider("Alpha (RR weight)", 0.0, 3.0, 1.0)
        beta = st.slider("Beta (BF weight)", 0.0, 3.0, 1.0)

        smile_thresh = row["ATM"] + alpha * row["RR"] + beta * row["BF"]
        st.metric("Smile-Adjusted Threshold", f"{smile_thresh:.4f}")

    with tab4_sub2:
        st.header("What is a Volatility Smile?")

        st.markdown("""
        ####  Simple Explanation:
        Markets expect **extreme price moves** (both up and down) to happen more often than average models assume.

        This leads to **higher implied volatility** for far out-of-the-money options â€” forming a curve that looks like a **smile**.
        
        ---
        ####  Smile Components:
        | Component | What it Means |
        |-----------|----------------|
        | **ATM Vol** | Market volatility when expecting no big move
        | **RR** (Risk Reversal) | Market fear of big up vs. big down moves
        | **BF** (Butterfly) | Market belief in extreme movements 

        ---
        ####  Why it Matters:
        - Manual thresholds don't reflect market mood.
        - Smile-based thresholds adapt to real risk pricing.
        - Especially important during global events or shocks.

        ---
        #### âœ… Example:
        If ATM = 0.20, RR = 0.03, BF = 0.02:

        `Smile Threshold = ATM + 1Ã—RR + 1Ã—BF = 0.25`

        If RR or BF changes (say market panics), the threshold also adapts!
        """)

        st.subheader("Example Visualization")
        ex_df = df_summary[df_summary["Currency"].isin(["INR", "JPY", "GBP"])]
        fig = px.bar(ex_df, x="Currency", y=["ManualThreshold", "Smile_Threshold"],
                     barmode="group", title="Manual vs Smile Threshold for Key Currencies")
        st.plotly_chart(fig, use_container_width=True)


with tab5:
    st.header("Smile Components Visualization")

    fig = px.scatter(df_summary, x="RR", y="BF", size="Smile_Threshold",
                     color="Currency", title="Smile Structure (RR vs BF)")
    st.plotly_chart(fig, use_container_width=True)

    fig2 = px.bar(df_summary, x="Currency", y=["ManualThreshold", "Smile_Threshold"],
                  barmode="group", title="Manual vs Smile Threshold")
    st.plotly_chart(fig2, use_container_width=True)

with tab6:
    st.header("Real-Time Recalibration Simulation")

    # Step 1: Create reuters_gfx_test_data.csv only once
    base_df = df.copy()
    impacted_currencies = ["INR", "JPY", "GBP"]
    shock_start = pd.to_datetime("2024-10-15")
    shock_end = pd.to_datetime("2024-11-01")

    df_test = base_df.copy()
    df_test["ShockFactor"] = 1.0
    df_test.loc[
        (df_test["Currency"].isin(impacted_currencies)) & (df_test["Date"] >= shock_start) & (df_test["Date"] <= shock_end),
        "ShockFactor"
    ] = np.random.normal(loc=1.5, scale=0.1, size=((df_test["Currency"].isin(impacted_currencies)) & (df_test["Date"] >= shock_start) & (df_test["Date"] <= shock_end)).sum())

    df_test["Close_Shocked"] = df_test["Close"] * df_test["ShockFactor"]
    df_test["LogReturn_Shocked"] = df_test.groupby("Currency")["Close_Shocked"].transform(lambda x: np.log(x).diff())
    df_test["Volatility"] = df_test.groupby("Currency")["LogReturn_Shocked"].transform(lambda x: x.rolling(ROLL_WINDOW).std()) * ANNUALIZE
    df_test = df_test.dropna()
    df_test[["Currency", "Date", "Close_Shocked", "Volatility"]].to_csv("reuters_gfx_test_data.csv", index=False)

    st.success("ðŸ“ `reuters_gfx_test_data.csv` created with shocked volatility.")

    # Step 2: Load and analyze
    st.subheader("Recalibrated Thresholds Using Test Data")
    test_df = pd.read_csv("reuters_gfx_test_data.csv")
    test_df["Date"] = pd.to_datetime(test_df["Date"])

    dynamic_recalibrated = test_df.groupby("Currency").agg(
        AvgVol_Shocked=("Volatility", "mean"),
        New95thPct=("Volatility", lambda x: x.quantile(PCT_THRESHOLD)),
        NewEVT=("Volatility", lambda x: genpareto.ppf(0.999, *genpareto.fit(x[x > x.quantile(EVT_TAIL_PCT)])))
    ).reset_index()

    merged = df_summary[["Currency", "ManualThreshold"]].merge(dynamic_recalibrated, on="Currency", how="inner")

    st.dataframe(merged, use_container_width=True)

    fig = px.bar(merged.melt(id_vars="Currency", value_vars=["ManualThreshold", "New95thPct", "NewEVT"]),
                 x="Currency", y="value", color="variable", barmode="group",
                 title="Manual vs Recalibrated Thresholds (Post-Volatility Shock)",
                 labels={"value": "Threshold", "variable": "Method"})
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("Insight")
    st.markdown("""
    - Manual thresholds remain unchanged despite post-Oct-2024 volatility spikes.
    - Recalibrated thresholds (95th Percentile, EVT) increase for impacted currencies.
    - This shows the importance of adaptive thresholds in real-time FX surveillance.
    """)
