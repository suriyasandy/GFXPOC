# --- PART 1: Imports, Global Configs, and Utility Caching ---
import streamlit as st
import pandas as pd
import numpy as np
import os, re
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from arch import arch_model
from scipy.stats import genpareto, kurtosis, skew
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense
from prophet import Prophet
from statsmodels.tsa.stattools import adfuller
import statsmodels.api as sm

ROLL_WINDOW = 60
ANNUALIZE = np.sqrt(252)
PCT_THRESHOLD = 0.95
EVT_TAIL_PCT = 0.995

# Page config
st.set_page_config(page_title="FX Volatility App", layout="wide")

# Background CSS
st.markdown("""
<style>
.stApp { background-color: black; }
</style>
""", unsafe_allow_html=True)

# Cache FX Data
@st.cache_data
def load_fx_data():
    df = pd.read_csv("reuters_fx_data.csv")
    df["Date"] = pd.to_datetime(df["Date"])
    df.sort_values(["Currency", "Date"], inplace=True)
    df["LogReturn"] = df.groupby("Currency")["Close"].transform(lambda x: np.log(x).diff())
    df["Volatility"] = df.groupby("Currency")["LogReturn"].transform(lambda x: x.rolling(ROLL_WINDOW).std()) * ANNUALIZE
    df["RealizedVol"] = df["OHLCVolatility"] / np.sqrt(252)
    return df.dropna()

df = load_fx_data()

# Assign manual volatility group
def assign_manual_group(vol):
    if vol < 0.07:
        return "Group 1"
    elif vol < 0.50:
        return "Group 2"
    elif vol < 0.60:
        return "Group 3"
    else:
        return "Group 4"

# --- PART 2: Threshold Summary (with Caching) and Prophet Optimization ---

@st.cache_data
def compute_thresholds_per_currency(df):
    summary = []
    for ccy, group in df.groupby("Currency"):
        # Volatility for dynamic models (unchanged)
        vol_series = group["Volatility"].dropna()
        avg_vol = vol_series.mean()

        # Manual group uses realized OHLC volatility
        realized_series = group["RealizedVol"].dropna()
        avg_realized_vol = realized_series.mean()

        # Manual group and threshold (based on OHLC-based logic)
        def assign_manual_group(vol):
            if vol < 0.07:
                return "Group 1"
            elif vol < 0.50:
                return "Group 2"
            elif vol < 0.60:
                return "Group 3"
            else:
                return "Group 4"

        manual_group = assign_manual_group(avg_realized_vol)
        manual_threshold = {
            "Group 1": 0.10,
            "Group 2": 0.25,
            "Group 3": 0.55,
            "Group 4": 0.80
        }[manual_group]

        try:
            am = arch_model(vol_series, vol='GARCH', p=1, q=1)
            res = am.fit(disp="off")
            forecast = res.forecast(horizon=1).variance.values[-1][0] ** 0.5
        except:
            forecast = np.nan

        tail_data = vol_series[vol_series > vol_series.quantile(EVT_TAIL_PCT)]
        try:
            evt_params = genpareto.fit(tail_data)
            evt_threshold = genpareto.ppf(0.999, *evt_params)
        except:
            evt_threshold = np.nan

        summary.append({
            "Currency": ccy,
            "AvgVol": avg_vol,
            "AvgRealizedVol": avg_realized_vol,
            "ManualGroup": manual_group,
            "ManualThreshold": manual_threshold,
            "GARCH_Forecast": forecast,
            "95th_Pct": vol_series.quantile(PCT_THRESHOLD),
            "EVT_Threshold": evt_threshold
        })
    return pd.DataFrame(summary)

df_summary = compute_thresholds_per_currency(df)

# --- Stationarity Check ---
def adf_stationarity_test(series):
    result = adfuller(series.dropna())
    return {
        "ADF Statistic": result[0],
        "p-value": result[1],
        "IsStationary": result[1] < 0.05
    }

# --- Prophet Forecast (Univariate) ---
@st.cache_data
def prophet_forecast_univariate(currency_data):
    df_prophet = currency_data[["Date", "Close"]].dropna().rename(columns={"Date": "ds", "Close": "y"})
    model = Prophet(seasonality_mode="multiplicative", daily_seasonality=True)
    model.fit(df_prophet)
    future = model.make_future_dataframe(periods=15)
    forecast = model.predict(future)
    return forecast, model

# --- Prophet Forecast (Multivariate) ---
@st.cache_data
def prophet_forecast_multivariate(currency_data):
    df_prophet = currency_data[["Date", "Close", "High", "Low"]].dropna().rename(
        columns={"Date": "ds", "Close": "y", "High": "add1", "Low": "add2"})
    model = Prophet(seasonality_mode="multiplicative", daily_seasonality=True)
    model.add_regressor("add1")
    model.add_regressor("add2")
    model.fit(df_prophet)
    future = df_prophet.drop(columns=["y"])
    forecast = model.predict(future)
    return forecast, model

# --- Seasonal Decomposition ---
def seasonal_decomposition_plot(df, currency, freq="W"):
    sub_df = df[df["Currency"] == currency][["Date", "Close"]].dropna()
    series = sub_df.set_index("Date")["Close"].resample(freq).mean().ffill()

    min_required = {"W": 104, "D": 730, "M": 24}[freq]
    if len(series) < min_required:
        st.warning(f"Not enough data for {freq} decomposition (found {len(series)}, need ≥ {min_required})")
        return

    result = sm.tsa.seasonal_decompose(series, model='multiplicative')
    fig = result.plot()
    plt.suptitle(f"{currency} Seasonal Decomposition ({freq})")
    st.pyplot(fig)
# --- PART 3: Tab 1 (Overview) and Tab 2 (Threshold Viewer) ---

# Tab layout
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "Overview", "Thresholds", "Live FX Rate Forecasting",
    "Final Results & Recommendation", "Cross-Currency View"
])

# --- Tab 1: Overview ---
with tab1:
    st.title("FX Volatility Thresholding: Manual vs Dynamic")

    st.subheader("Business Use Case")
    st.markdown("""
    In institutional FX markets, trades are monitored for **rate deviations** from market benchmarks.
    A key component of this is **volatility thresholding**, which helps:
    - Flag trades with excessive deviation.
    - Ensure fairness, reduce risk, and maintain compliance.

    Currently, operations teams use **static thresholds** per currency, based on manual grouping logic.
    But these thresholds:
    - Don’t adapt to changing market conditions.
    - Fail to account for structural behaviors like **volatility clustering** or **option smiles**.
    """)

    st.subheader("Manual Approach (Baseline)")
    st.markdown("""
    - Currencies are bucketed into 4 fixed groups (based on average volatility ranges).
    - Each group has a fixed threshold (e.g., 0.10, 0.25...).
    - These thresholds are static and reviewed annually or post-incident.

    **Limitations**:
    - Outdated during regime shifts.
    - Not tailored to individual currency behavior.
    - No support for cross-currency or structural features like skew or RR/BF.
    """)

    st.subheader("Our Dynamic Approach")
    st.markdown("""
    We simulate and compare **multiple thresholding methods**:
    - GARCH: Captures volatility clustering.
    - EVT: Captures extreme tail risks.
    - Rolling statistics & 95th percentile comparisons.

    All results are:
    - Transparent & visual.
    - Easy to interpret.
    - Designed for **weekly recalibration** instead of static thresholds.
    """)

    st.success("Use the tabs above to compare manual thresholds with smarter, data-driven models!")

# --- Tab 2: Threshold Comparison ---
with tab2:
    st.header("Threshold Comparison Summary")

    st.dataframe(df_summary[[
        "Currency", "AvgVol", "AvgRealizedVol", "ManualGroup",
        "ManualThreshold", "GARCH_Forecast", "95th_Pct", "EVT_Threshold"
    ]], use_container_width=True)

    sel = st.selectbox("Select Currency", df_summary["Currency"], key="tab2_currency")
    series = df[df["Currency"] == sel].copy()
    summary = df_summary[df_summary["Currency"] == sel].iloc[0]

    fig = px.line(series, x="Date", y="Volatility", title=f"{sel} Volatility & Thresholds (LogReturn-based)")
    for label in ["ManualThreshold", "GARCH_Forecast", "95th_Pct", "EVT_Threshold"]:
        val = summary[label]
        if pd.notnull(val):
            fig.add_hline(y=val, line_dash="dot", annotation_text=label)

    # Overlay Ops-style volatility (Realized)
    fig.add_trace(go.Scatter(
        x=series["Date"], y=series["RealizedVol"],
        name="RealizedVol (Ops-style)", line=dict(dash="dash", color="orange")
    ))

    st.plotly_chart(fig, use_container_width=True)

    st.markdown(f"""
    **Notes**:
    - `Volatility`: Based on log-returns (used in GARCH, EVT, 95th).
    - `RealizedVol`: Based on OHLC, used by Ops for manual grouping.
    - `ManualThreshold`: Based on `RealizedVol` average.
    """)


with tab3:
    st.header("Live FX Forecasting (Train: Jan–Aug, Test: Sep–Oct 2024)")

    selected_currency = st.selectbox("Select Currency", df["Currency"].unique(), key="fx_forecast_currency")
    if selected_currency:
        df_ccy = df[df["Currency"] == selected_currency][["Date", "Close"]].dropna().copy()
        df_ccy["Date"] = pd.to_datetime(df_ccy["Date"])
        df_ccy.set_index("Date", inplace=True)

        # Split into Train and Test
        train_df = df_ccy[df_ccy.index < "2024-09-01"]
        test_df = df_ccy[df_ccy.index >= "2024-09-01"]

        scaler = MinMaxScaler()
        scaled_all = scaler.fit_transform(df_ccy)
        scaled_train = scaler.transform(train_df)
        scaled_test = scaler.transform(test_df)

        # --- Sequence Generator ---
        def create_sequences(data, window):
            X, y = [], []
            for i in range(len(data) - window):
                X.append(data[i:i+window])
                y.append(data[i+window])
            return np.array(X), np.array(y)

        WINDOW = 30
        X_train, y_train = create_sequences(scaled_train, WINDOW)
        X_train_rf = X_train.reshape(X_train.shape[0], -1)
        X_train_lstm = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)

        # Generate test windows from end of train + test
        X_rf_test = []
        for i in range(len(test_df)):
            X_rf_test.append(scaled_all[-(len(test_df) + WINDOW - i):-len(test_df) + i])
        X_rf_test = np.array(X_rf_test).reshape(len(X_rf_test), -1)
        X_lstm_test = np.array([x.reshape(WINDOW, 1) for x in X_rf_test])

        # --- Model Training ---
        model_outputs_train, model_outputs_test = {}, {}

        # RF
        rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)
        rf.fit(X_train_rf, y_train.ravel())
        model_outputs_train["Random Forest"] = rf.predict(X_train_rf)
        model_outputs_test["Random Forest"] = rf.predict(X_rf_test)

        # LSTM
        lstm = Sequential()
        lstm.add(LSTM(64, input_shape=(WINDOW, 1)))
        lstm.add(Dropout(0.2))
        lstm.add(Dense(1))
        lstm.compile(optimizer="adam", loss="mse")
        lstm.fit(X_train_lstm, y_train, epochs=20, batch_size=16, verbose=0)
        model_outputs_train["LSTM"] = lstm.predict(X_train_lstm).ravel()
        model_outputs_test["LSTM"] = lstm.predict(X_lstm_test).ravel()

        # Linear Regression
        lr = LinearRegression()
        lr.fit(X_train_rf, y_train)
        model_outputs_train["Linear Regression"] = lr.predict(X_train_rf)
        model_outputs_test["Linear Regression"] = lr.predict(X_rf_test)

        y_true_train = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()
        y_true_test = test_df["Close"].values

        # --- Plot Train + Test Predictions ---
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=train_df.index[-len(y_true_train):], y=y_true_train, name="Actual (Train)", line=dict(color="white")))
        fig.add_trace(go.Scatter(x=test_df.index, y=y_true_test, name="Actual (Test)", line=dict(color="white", dash="dot")))

        metrics = []
        for model, preds_train in model_outputs_train.items():
            preds_train_inv = scaler.inverse_transform(preds_train.reshape(-1, 1)).flatten()
            preds_test_inv = scaler.inverse_transform(model_outputs_test[model].reshape(-1, 1)).flatten()

            # Add to chart
            fig.add_trace(go.Scatter(x=train_df.index[-len(y_true_train):], y=preds_train_inv, name=f"{model} (Train)", line=dict(dash="dash")))
            fig.add_trace(go.Scatter(x=test_df.index, y=preds_test_inv, name=f"{model} (Test)", line=dict(dash="solid")))

            metrics.append({
                "Model": model,
                "Train MAPE": mean_absolute_percentage_error(y_true_train, preds_train_inv) * 100,
                "Test MAPE": mean_absolute_percentage_error(y_true_test, preds_test_inv) * 100,
                "Train RMSE": np.sqrt(mean_squared_error(y_true_train, preds_train_inv)),
                "Test RMSE": np.sqrt(mean_squared_error(y_true_test, preds_test_inv))
            })

        # Overlay manual threshold for reference
        manual_thresh = df_summary[df_summary["Currency"] == selected_currency]["ManualThreshold"].values[0]
        fig.add_hline(y=manual_thresh, line_color="red", line_dash="dot", annotation_text="Manual Threshold")

        # Derive dynamic bounds
        best_model = min(metrics, key=lambda x: x["Test MAPE"])
        model_name = best_model["Model"]
        preds_inv = scaler.inverse_transform(
            model_outputs_test[model_name].reshape(-1, 1)
        ).flatten()
        mape_pct = best_model["Test MAPE"] / 100

        upper_bound = preds_inv * (1 + mape_pct)
        lower_bound = preds_inv * (1 - mape_pct)

        # Identify flags
        flag_mask = (y_true_test > upper_bound) | (y_true_test < lower_bound)

        fig.add_trace(go.Scatter(x=test_df.index, y=upper_bound, name="Dynamic Upper", line=dict(dash="dot", color="green")))
        fig.add_trace(go.Scatter(x=test_df.index, y=lower_bound, name="Dynamic Lower", line=dict(dash="dot", color="green")))

        # Plot flagged points as red markers
        fig.add_trace(go.Scatter(
            x=test_df.index[flag_mask],
            y=y_true_test[flag_mask],
            mode="markers",
            name="Flagged Deviations",
            marker=dict(color="red", size=10, symbol="x")
        ))

        fig.add_hline(y=manual_thresh, line_color="red", line_dash="dot", annotation_text="Manual Threshold")

        fig.update_layout(
            title=f"{selected_currency}: Forecast vs Thresholds ({model_name})",
            xaxis_title="Date",
            yaxis_title="FX Rate"
        )
        st.plotly_chart(fig, use_container_width=True)


with tab4:
    st.header("Final Thresholds & Forecast Accuracy")

    df_summary["FinalThreshold"] = df_summary[[ 
        "ManualThreshold", "95th_Pct", "GARCH_Forecast", "EVT_Threshold"
    ]].max(axis=1)

    @st.cache_data
    def load_best_mape_summary():
        try:
            log_df = pd.read_csv("model_feedback_log.csv")
            latest = log_df.sort_values("RunDate", ascending=False).drop_duplicates(subset=["Currency", "Model"])
            best_mape = latest.groupby("Currency")["MAPE"].min().reset_index()
            best_mape.rename(columns={"MAPE": "Best_MAPE"}, inplace=True)
            return best_mape
        except:
            return pd.DataFrame(columns=["Currency", "Best_MAPE"])

    best_mape_df = load_best_mape_summary()
    df_final = df_summary.merge(best_mape_df, on="Currency", how="left")

    selected_currency = st.selectbox("Select Currency", df_final["Currency"], key="tab4_currency")
    row = df_final[df_final["Currency"] == selected_currency].iloc[0]

    st.subheader(f"{selected_currency}: Thresholds & Justification")
    st.markdown(f"""
    - **Avg Log-Return Volatility** (Dynamic): `{round(row['AvgVol'], 4)}`
    - **Avg OHLC Realized Volatility** (Manual): `{round(row['AvgRealizedVol'], 4)}`
    - **Manual Group (based on OHLC)**: `{row['ManualGroup']}`
    - **Manual Threshold**: `{round(row['ManualThreshold'], 4)}`
    - **Final Dynamic Threshold** (Max of Models): `{round(row['FinalThreshold'], 4)}`
    - **Best Model MAPE**: `{round(row['Best_MAPE'], 2)}%`
    """)

    # --- Bar Plot: Thresholds & Best MAPE ---
    fig = go.Figure()
    fig.add_trace(go.Bar(name="Manual", x=[selected_currency], y=[row["ManualThreshold"]]))
    fig.add_trace(go.Bar(name="Final Dynamic", x=[selected_currency], y=[row["FinalThreshold"]]))
    fig.add_trace(go.Bar(name="Best Model MAPE", x=[selected_currency], y=[row["Best_MAPE"] / 100]))
    fig.update_layout(title="Threshold Comparison", barmode="group")
    st.plotly_chart(fig, use_container_width=True)

    # --- Volatility Trend with Thresholds & MAPE Band ---
    st.subheader("Historical Volatility Trend & Breach Flags")
    trend_df = df[df["Currency"] == selected_currency].copy()
    trend_df = trend_df.sort_values("Date")
    y_actual = trend_df["Volatility"].values
    dates = trend_df["Date"]

    best_mape = row["Best_MAPE"] or 0
    mape_pct = best_mape / 100

    upper_band = y_actual * (1 + mape_pct)
    lower_band = y_actual * (1 - mape_pct)
    flag_mask = (y_actual > upper_band) | (y_actual < lower_band)

    fig_vol = go.Figure()
    fig_vol.add_trace(go.Scatter(x=dates, y=y_actual, name="Actual Volatility", line=dict(color="white")))
    fig_vol.add_trace(go.Scatter(x=dates, y=upper_band, name="Dynamic Upper", line=dict(dash="dot", color="green")))
    fig_vol.add_trace(go.Scatter(x=dates, y=lower_band, name="Dynamic Lower", line=dict(dash="dot", color="green")))
    fig_vol.add_hline(y=row["ManualThreshold"], line_color="red", line_dash="dot", annotation_text="Manual")
    fig_vol.add_hline(y=row["FinalThreshold"], line_color="orange", line_dash="dash", annotation_text="Final Dynamic")

    # Deviation flags
    fig_vol.add_trace(go.Scatter(
        x=dates[flag_mask],
        y=y_actual[flag_mask],
        mode="markers",
        name="Flagged Deviations",
        marker=dict(color="red", size=8, symbol="x")
    ))

    fig_vol.update_layout(
        title=f"{selected_currency}: Volatility with Manual, Dynamic Thresholds & Flags",
        xaxis_title="Date",
        yaxis_title="Annualized Volatility"
    )
    st.plotly_chart(fig_vol, use_container_width=True)


# --- Tab 5: Cross-Currency Threshold Estimation ---
with tab5:
    st.header("Cross-Currency Thresholds (Synthetic)")

    st.markdown("""
    This module calculates cross-currency thresholds (e.g., INRJPY) using their USD legs (e.g., INRUSD + USDJPY).
    """)

    cross_pairs = [("INRJPY", "INR", "JPY"), ("GBPJPY", "GBP", "JPY"), ("EURINR", "EUR", "INR")]
    pair_labels = [f"{p[0]} = {p[1]}USD × USD{p[2]}" for p in cross_pairs]
    pair_choice = st.selectbox("Select Cross Pair", pair_labels)

    selected_pair = cross_pairs[pair_labels.index(pair_choice)]
    pair_name, base_ccy, quote_ccy = selected_pair

    base_df = df[df["Currency"] == base_ccy][["Date", "Close", "Volatility"]].copy()
    quote_df = df[df["Currency"] == quote_ccy][["Date", "Close", "Volatility"]].copy()
    merged = pd.merge(base_df, quote_df, on="Date", suffixes=(f"_{base_ccy}", f"_{quote_ccy}")).dropna()

    merged["SyntheticRate"] = merged[f"Close_{base_ccy}"] / merged[f"Close_{quote_ccy}"]
    merged["LogReturn"] = np.log(merged["SyntheticRate"]).diff()
    merged["CrossVolatility"] = merged["LogReturn"].rolling(ROLL_WINDOW).std() * ANNUALIZE
    merged.dropna(inplace=True)

    df_thresh = df_summary.set_index("Currency")
    manual_cross = max(df_thresh.loc[base_ccy, "ManualThreshold"], df_thresh.loc[quote_ccy, "ManualThreshold"])
    dynamic_cross = max(df_thresh.loc[base_ccy, "FinalThreshold"], df_thresh.loc[quote_ccy, "FinalThreshold"])

    st.subheader(f"{pair_name} Thresholds")
    st.markdown(f"""
    - **Cross Volatility Range**: `{merged['CrossVolatility'].min():.4f}` to `{merged['CrossVolatility'].max():.4f}`
    - **Manual Cross Threshold**: `{manual_cross:.4f}`
    - **Final Dynamic Threshold (max of legs)**: `{dynamic_cross:.4f}`
    """)

    fig = px.line(merged, x="Date", y="CrossVolatility", title=f"{pair_name} Volatility (Synthetic)")
    fig.add_hline(y=manual_cross, line_color="red", line_dash="dot", annotation_text="Manual")
    fig.add_hline(y=dynamic_cross, line_color="green", line_dash="dash", annotation_text="Dynamic")
    st.plotly_chart(fig, use_container_width=True)
